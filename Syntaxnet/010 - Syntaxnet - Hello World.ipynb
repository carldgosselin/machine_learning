{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntaxnet - Hello World\n",
    "Run the final test after successfully installing Syntaxnet and related components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use %%bash to run command line commands in this Python notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Bob brought the pizza to Alice\n",
      "Parse:\n",
      "brought VBD ROOT\n",
      " +-- Bob NNP nsubj\n",
      " +-- pizza NN dobj\n",
      " |   +-- the DT det\n",
      " +-- to IN prep\n",
      "     +-- Alice NNP pobj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I syntaxnet/term_frequency_map.cc:103] Loaded 46 terms from syntaxnet/models/parsey_mcparseface/label-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 46 terms from syntaxnet/models/parsey_mcparseface/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: input.digit input.hyphen; input.prefix(length=\"2\") input(1).prefix(length=\"2\") input(2).prefix(length=\"2\") input(3).prefix(length=\"2\") input(-1).prefix(length=\"2\") input(-2).prefix(length=\"2\") input(-3).prefix(length=\"2\") input(-4).prefix(length=\"2\"); input.prefix(length=\"3\") input(1).prefix(length=\"3\") input(2).prefix(length=\"3\") input(3).prefix(length=\"3\") input(-1).prefix(length=\"3\") input(-2).prefix(length=\"3\") input(-3).prefix(length=\"3\") input(-4).prefix(length=\"3\"); input.suffix(length=\"2\") input(1).suffix(length=\"2\") input(2).suffix(length=\"2\") input(3).suffix(length=\"2\") input(-1).suffix(length=\"2\") input(-2).suffix(length=\"2\") input(-3).suffix(length=\"2\") input(-4).suffix(length=\"2\"); input.suffix(length=\"3\") input(1).suffix(length=\"3\") input(2).suffix(length=\"3\") input(3).suffix(length=\"3\") input(-1).suffix(length=\"3\") input(-2).suffix(length=\"3\") input(-3).suffix(length=\"3\") input(-4).suffix(length=\"3\"); input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: other;prefix2;prefix3;suffix2;suffix3;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 8;16;16;16;16;64\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.child(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;tags;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 49 terms from syntaxnet/models/parsey_mcparseface/tag-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 64036 terms from syntaxnet/models/parsey_mcparseface/word-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [12 20 20] domain_sizes: [   49    51 64038]\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 64036 terms from syntaxnet/models/parsey_mcparseface/word-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 49 terms from syntaxnet/models/parsey_mcparseface/tag-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [2 8 8 8 8 8] domain_sizes: [    5 10665 10665  8970  8970 64038]\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 46 terms from syntaxnet/models/parsey_mcparseface/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.child(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;tags;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 49 terms from syntaxnet/models/parsey_mcparseface/tag-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 64036 terms from syntaxnet/models/parsey_mcparseface/word-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 49 terms from syntaxnet/models/parsey_mcparseface/tag-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 46 terms from syntaxnet/models/parsey_mcparseface/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: input.digit input.hyphen; input.prefix(length=\"2\") input(1).prefix(length=\"2\") input(2).prefix(length=\"2\") input(3).prefix(length=\"2\") input(-1).prefix(length=\"2\") input(-2).prefix(length=\"2\") input(-3).prefix(length=\"2\") input(-4).prefix(length=\"2\"); input.prefix(length=\"3\") input(1).prefix(length=\"3\") input(2).prefix(length=\"3\") input(3).prefix(length=\"3\") input(-1).prefix(length=\"3\") input(-2).prefix(length=\"3\") input(-3).prefix(length=\"3\") input(-4).prefix(length=\"3\"); input.suffix(length=\"2\") input(1).suffix(length=\"2\") input(2).suffix(length=\"2\") input(3).suffix(length=\"2\") input(-1).suffix(length=\"2\") input(-2).suffix(length=\"2\") input(-3).suffix(length=\"2\") input(-4).suffix(length=\"2\"); input.suffix(length=\"3\") input(1).suffix(length=\"3\") input(2).suffix(length=\"3\") input(3).suffix(length=\"3\") input(-1).suffix(length=\"3\") input(-2).suffix(length=\"3\") input(-3).suffix(length=\"3\") input(-4).suffix(length=\"3\"); input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: other;prefix2;prefix3;suffix2;suffix3;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 8;16;16;16;16;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 64036 terms from syntaxnet/models/parsey_mcparseface/word-map.\n",
      "INFO:tensorflow:Processed 1 documents\n",
      "INFO:tensorflow:Total processed documents: 1\n",
      "INFO:tensorflow:num correct tokens: 0\n",
      "INFO:tensorflow:total tokens: 6\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 0.12, eval metric: 0.00%\n",
      "INFO:tensorflow:Processed 1 documents\n",
      "INFO:tensorflow:Total processed documents: 1\n",
      "INFO:tensorflow:num correct tokens: 1\n",
      "INFO:tensorflow:total tokens: 6\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 0.57, eval metric: 16.67%\n",
      "INFO:tensorflow:Read 1 documents\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo 'Bob brought the pizza to Alice' | syntaxnet/demo.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
