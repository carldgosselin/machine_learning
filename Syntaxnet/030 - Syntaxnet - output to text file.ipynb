{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntaxnet - Output to text file\n",
    "You have the option of outputting the resulting data into a text file <br>\n",
    "\n",
    "There are many options to outputting the results into a text file. One option is to hardcode the output file within the Syntaxnet files. With this option, you will need to make changes to both demo.sh and context.pbtxt\n",
    "\n",
    "Another option, which I prefer at the moment, is to redirect the output from the command line by appending the following \"> path/filename.txt\"\n",
    "\n",
    "example-> echo 'Bob brought the pizza to Alice' | syntaxnet/demo_carl2.sh > carl/test/test_output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Remove scroll bar when result window exceeds limit by extending scroll threshold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use %%bash to run command line commands in this Python notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following has been saved to a file called test_output.txt...\n",
      "\n",
      "1\tBob\t_\tNOUN\tNNP\t_\t2\tnsubj\t_\t_\n",
      "2\tbrought\t_\tVERB\tVBD\t_\t0\tROOT\t_\t_\n",
      "3\tthe\t_\tDET\tDT\t_\t4\tdet\t_\t_\n",
      "4\tpizza\t_\tNOUN\tNN\t_\t2\tdobj\t_\t_\n",
      "5\tto\t_\tADP\tIN\t_\t2\tprep\t_\t_\n",
      "6\tAlice\t_\tNOUN\tNNP\t_\t5\tpobj\t_\t_\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I syntaxnet/term_frequency_map.cc:103] Loaded 46 terms from syntaxnet/models/parsey_mcparseface/label-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 46 terms from syntaxnet/models/parsey_mcparseface/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: input.digit input.hyphen; input.prefix(length=\"2\") input(1).prefix(length=\"2\") input(2).prefix(length=\"2\") input(3).prefix(length=\"2\") input(-1).prefix(length=\"2\") input(-2).prefix(length=\"2\") input(-3).prefix(length=\"2\") input(-4).prefix(length=\"2\"); input.prefix(length=\"3\") input(1).prefix(length=\"3\") input(2).prefix(length=\"3\") input(3).prefix(length=\"3\") input(-1).prefix(length=\"3\") input(-2).prefix(length=\"3\") input(-3).prefix(length=\"3\") input(-4).prefix(length=\"3\"); input.suffix(length=\"2\") input(1).suffix(length=\"2\") input(2).suffix(length=\"2\") input(3).suffix(length=\"2\") input(-1).suffix(length=\"2\") input(-2).suffix(length=\"2\") input(-3).suffix(length=\"2\") input(-4).suffix(length=\"2\"); input.suffix(length=\"3\") input(1).suffix(length=\"3\") input(2).suffix(length=\"3\") input(3).suffix(length=\"3\") input(-1).suffix(length=\"3\") input(-2).suffix(length=\"3\") input(-3).suffix(length=\"3\") input(-4).suffix(length=\"3\"); input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.cI syntaxnet/embedding_feature_extractor.cc:36] Embedding names: other;prefix2;prefix3;suffix2;suffix3;words\n",
      "hild(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;tags;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;64\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 8;16;16;16;16;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 49 terms from syntaxnet/models/parsey_mcparseface/tag-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 64036 terms from syntaxnet/models/parsey_mcparseface/word-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 64036 terms from syntaxnet/models/parsey_mcparseface/word-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 49 terms from syntaxnet/models/parsey_mcparseface/tag-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [12 20 20] domain_sizes: [   49    51 64038]\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [2 8 8 8 8 8] domain_sizes: [    5 10665 10665  8970  8970 64038]\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 46 terms from syntaxnet/models/parsey_mcparseface/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.child(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;tags;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 49 terms from syntaxnet/models/parsey_mcparseface/tag-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 64036 terms from syntaxnet/models/parsey_mcparseface/word-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 49 terms from syntaxnet/models/parsey_mcparseface/tag-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 46 terms from syntaxnet/models/parsey_mcparseface/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: input.digit input.hyphen; input.prefix(length=\"2\") input(1).prefix(length=\"2\") input(2).prefix(length=\"2\") input(3).prefix(length=\"2\") input(-1).prefix(length=\"2\") input(-2).prefix(length=\"2\") input(-3).prefix(length=\"2\") input(-4).prefix(length=\"2\"); input.prefix(length=\"3\") input(1).prefix(length=\"3\") input(2).prefix(length=\"3\") input(3).prefix(length=\"3\") input(-1).prefix(length=\"3\") input(-2).prefix(length=\"3\") input(-3).prefix(length=\"3\") input(-4).prefix(length=\"3\"); input.suffix(length=\"2\") input(1).suffix(length=\"2\") input(2).suffix(length=\"2\") input(3).suffix(length=\"2\") input(-1).suffix(length=\"2\") input(-2).suffix(length=\"2\") input(-3).suffix(length=\"2\") input(-4).suffix(length=\"2\"); input.suffix(length=\"3\") input(1).suffix(length=\"3\") input(2).suffix(length=\"3\") input(3).suffix(length=\"3\") input(-1).suffix(length=\"3\") input(-2).suffix(length=\"3\") input(-3).suffix(length=\"3\") input(-4).suffix(length=\"3\"); input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: other;prefix2;prefix3;suffix2;suffix3;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 8;16;16;16;16;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 64036 terms from syntaxnet/models/parsey_mcparseface/word-map.\n",
      "INFO:tensorflow:Processed 1 documents\n",
      "INFO:tensorflow:Total processed documents: 1\n",
      "INFO:tensorflow:num correct tokens: 0\n",
      "INFO:tensorflow:total tokens: 6\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 0.13, eval metric: 0.00%\n",
      "INFO:tensorflow:Processed 1 documents\n",
      "INFO:tensorflow:Total processed documents: 1\n",
      "INFO:tensorflow:num correct tokens: 1\n",
      "INFO:tensorflow:total tokens: 6\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 0.63, eval metric: 16.67%\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 46 terms from syntaxnet/models/parsey_mcparseface/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.child(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;tags;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 49 terms from syntaxnet/models/parsey_mcparseface/tag-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 46 terms from syntaxnet/models/parsey_mcparseface/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: input.digit input.hyphen; input.prefix(length=\"2\") input(1).prefix(length=\"2\") input(2).prefix(length=\"2\") input(3).prefix(length=\"2\") input(-1).prefix(length=\"2\") input(-2).prefix(length=\"2\") input(-3).prefix(length=\"2\") input(-4).prefix(length=\"2\"); input.prefix(length=\"3\") input(1).prefix(length=\"3\") input(2).prefix(length=\"3\") input(3).prefix(length=\"3\") input(-1).prefix(length=\"3\") input(-2).prefix(length=\"3\") input(-3).prefix(length=\"3\") input(-4).prefix(length=\"3\"); input.suffix(length=\"2\") input(1).suffix(length=\"2\") input(2).suffix(length=\"2\") input(3).suffix(length=\"2\") input(-1).suffix(length=\"2\") input(-2).suffix(length=\"2\") input(-3).suffix(length=\"2\") input(-4).suffix(length=\"2\"); input.suffix(length=\"3\") input(1).suffix(length=\"3\") input(2).suffix(length=\"3\") input(3).suffix(length=\"3\") input(-1).suffix(length=\"3\") input(-2).suffix(length=\"3\") input(-3).suffix(length=\"3\") input(-4).suffix(length=\"3\"); input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: other;prefix2;prefix3;suffix2;suffix3;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 8;16;16;16;16;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 64036 terms from syntaxnet/models/parsey_mcparseface/word-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [12 20 20] domain_sizes: [   49    51 64038]\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 64036 terms from syntaxnet/models/parsey_mcparseface/word-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 49 terms from syntaxnet/models/parsey_mcparseface/tag-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [2 8 8 8 8 8] domain_sizes: [    5 10665 10665  8970  8970 64038]\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 46 terms from syntaxnet/models/parsey_mcparseface/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.child(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;tags;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 49 terms from syntaxnet/models/parsey_mcparseface/tag-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 64036 terms from syntaxnet/models/parsey_mcparseface/word-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 49 terms from syntaxnet/models/parsey_mcparseface/tag-map.\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 46 terms from syntaxnet/models/parsey_mcparseface/label-map.\n",
      "I syntaxnet/embedding_feature_extractor.cc:35] Features: input.digit input.hyphen; input.prefix(length=\"2\") input(1).prefix(length=\"2\") input(2).prefix(length=\"2\") input(3).prefix(length=\"2\") input(-1).prefix(length=\"2\") input(-2).prefix(length=\"2\") input(-3).prefix(length=\"2\") input(-4).prefix(length=\"2\"); input.prefix(length=\"3\") input(1).prefix(length=\"3\") input(2).prefix(length=\"3\") input(3).prefix(length=\"3\") input(-1).prefix(length=\"3\") input(-2).prefix(length=\"3\") input(-3).prefix(length=\"3\") input(-4).prefix(length=\"3\"); input.suffix(length=\"2\") input(1).suffix(length=\"2\") input(2).suffix(length=\"2\") input(3).suffix(length=\"2\") input(-1).suffix(length=\"2\") input(-2).suffix(length=\"2\") input(-3).suffix(length=\"2\") input(-4).suffix(length=\"2\"); input.suffix(length=\"3\") input(1).suffix(length=\"3\") input(2).suffix(length=\"3\") input(3).suffix(length=\"3\") input(-1).suffix(length=\"3\") input(-2).suffix(length=\"3\") input(-3).suffix(length=\"3\") input(-4).suffix(length=\"3\"); input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word \n",
      "I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: other;prefix2;prefix3;suffix2;suffix3;words\n",
      "I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 8;16;16;16;16;64\n",
      "I syntaxnet/term_frequency_map.cc:103] Loaded 64036 terms from syntaxnet/models/parsey_mcparseface/word-map.\n",
      "INFO:tensorflow:Processed 1 documents\n",
      "INFO:tensorflow:Total processed documents: 1\n",
      "INFO:tensorflow:num correct tokens: 0\n",
      "INFO:tensorflow:total tokens: 6\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 0.13, eval metric: 0.00%\n",
      "INFO:tensorflow:Processed 1 documents\n",
      "INFO:tensorflow:Total processed documents: 1\n",
      "INFO:tensorflow:num correct tokens: 1\n",
      "INFO:tensorflow:total tokens: 6\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 0.64, eval metric: 16.67%\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo 'Bob brought the pizza to Alice' | syntaxnet/demo_carl2.sh > carl/test/test_output.txt\n",
    "\n",
    "printf \"\\nThe following has been saved to a file called test_output.txt...\\n\\n\"\n",
    "echo 'Bob brought the pizza to Alice' | syntaxnet/demo_carl2.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
