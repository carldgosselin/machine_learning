{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract names from doc - baseline\n",
    "\n",
    "The following solution utilizes a basic sequential approach to finding the party names in an agreement.<br>\n",
    "Format:  Agreement Name, Party1:  YOU, Party2: Apple\n",
    "\n",
    "For this baseline solution, **Syntaxnet** and **Machine Learning** are **NOT** utilized.  \n",
    "These techniques will be used in the next iterations to improve on the baseline performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenges with current baseline solution:**\n",
    "- Does not capure party names that contain multiple words\n",
    "- Current logic captures the first word after \"between\" for the first party and \"and\" for the second party.  One of the test cases captured the word \"the\" as opposed to the party name.\n",
    "- The major challenge in this approach is adding lines of codes to handle the nuances in the writing style of each agreement. This can result in almost limitless lines of code.\n",
    "\n",
    "**Conclusion**: A more sophisticated solution is needed. Google's Syntaxnet could be applied to process and identify word types/dependencies in a sentence.  These dependencies can then be used to retrieve the correct party names.  Another alternative could be to process the agreement text via a machine learning approach.  With machine learning, an algorithm can be trained to process text and identify target labels (aka party names).  Once an algorithm is successfully trained, the algorithm can be applied to extract party names on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Adjust scroll bar activation threshold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 100;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agreements data read successfully! \n",
      "\n",
      "Selected text file name from csv ->  CareerBuilder_eula.txt \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose agreement file from list in csv\n",
    "\n",
    "# read csv file\n",
    "agreements_data = pd.read_csv(\"data/agreements_dataset1.csv\")\n",
    "print \"\\n\",\"Agreements data read successfully!\",\"\\n\"\n",
    "\n",
    "# Select text file name\n",
    "selected_text_file_name = agreements_data['file_name'][16]\n",
    "print \"Selected text file name from csv -> \", selected_text_file_name, \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agreement text has been cleansed and parsed into separate sentences. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cleanse and parse text into separate sentences\n",
    "\n",
    "caps = \"([A-Z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr|www|1|2|2|3|4|5|6|7|8|9|10)[.]\"\n",
    "suffixes = \"(Inc|INC|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = text.replace(\"\\r\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + caps + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + caps + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences\n",
    "\n",
    "filepath = \"data/\" + selected_text_file_name\n",
    "with open(filepath, 'r') as my_agreement:\n",
    "    my_agreement_text=my_agreement.read()\n",
    "\n",
    "my_agreement_lines = split_into_sentences(my_agreement_text)\n",
    "\n",
    "print \"\\n\", \"Agreement text has been cleansed and parsed into separate sentences.\", \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of sentences retrieved: 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find sentences with \"between\"\n",
    "\n",
    "key_sentences = []\n",
    "type_of_sentence = \"\"\n",
    "key_words = [\"between\"]\n",
    "Party1 = \"not found yet\"\n",
    "Party2 = \"not found yet\"\n",
    "\n",
    "for line in my_agreement_lines:\n",
    "    for word in key_words:\n",
    "        if word in line.lower(): \n",
    "            key_sentences.append(line)\n",
    "                \n",
    "print \"\\n\", \"Number of sentences retrieved:\", len(key_sentences),  \"\\n\"\n",
    "# print \"\\n\", key_sentences, \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agreement: CareerBuilder_eula.txt\n",
      "Party1: you , Party2: CareerBuilder \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Identify number of sentences retrieved\n",
    "\n",
    "def summary():\n",
    "    print \"\\n\", \"Agreement:\", selected_text_file_name\n",
    "    print \"Party1:\",Party1,\",\",\"Party2:\",Party2,\"\\n\"\n",
    "\n",
    "\n",
    "if len(key_sentences) == 0: \n",
    "    print \"There is no 'between' clause in the document\"\n",
    "    print \"Party1 ->\",Party1\n",
    "    print \"Party2 ->\",Party2\n",
    "    \n",
    "if len(key_sentences) == 1: \n",
    "\n",
    "    match1 = re.search(r'between (\\w+)', key_sentences[0])\n",
    "    after_match1 = re.search(r'between (.*)', key_sentences[0])\n",
    "    match2 = re.search(r'and (\\w+)', after_match1.group(1))\n",
    "    \n",
    "    Party1 = match1.group(1)\n",
    "    Party2 = match2.group(1) \n",
    "    summary()\n",
    "    \n",
    "if len(key_sentences) > 1: \n",
    "    \n",
    "    key_sentences2 = []\n",
    "    listOfWords = ['between','agreement']\n",
    "\n",
    "    for line in key_sentences:\n",
    "        if all(word in line.lower() for word in listOfWords):\n",
    "            key_sentences2.append(line)\n",
    "    \n",
    "    if len(key_sentences2) == 0:\n",
    "        print \"no key sentences returned.\"\n",
    "        \n",
    "    if len(key_sentences2) == 1:\n",
    "        \n",
    "        match1 = re.search(r'between (\\w+)', key_sentences[0])\n",
    "        after_match1 = re.search(r'between (.*)', key_sentences[0])\n",
    "        match2 = re.search(r'and (\\w+)', after_match1.group(1))\n",
    "        \n",
    "        Party1 = match1.group(1)\n",
    "        Party2 = match2.group(1)\n",
    "        summary()\n",
    "        \n",
    "    if len(key_sentences2) > 1:\n",
    "        print \"Number of sentences retrieved:\", len(key_sentences2)\n",
    "        print \"Processing the first retrieved sentence\"\n",
    "        # print key_sentences2\n",
    "        \n",
    "        match1 = re.search(r'between (\\w+)', key_sentences2[0], flags=re.I) # re.I -> ignore upper/lower case\n",
    "        after_match1 = re.search(r'between (.*)', key_sentences2[0], flags=re.I)\n",
    "        match2 = re.search(r'and (\\w+)', after_match1.group(1), flags=re.I)\n",
    "    \n",
    "        Party1 = match1.group(1)\n",
    "        Party2 = match2.group(1)\n",
    "        summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Successful extracts**\n",
    "\n",
    "1. ABBYY_eula.txt, Party1: you , Party2: ABBYY \n",
    "2. Aeria Games & Entertainment Inc_eula.txt, Party1: Licensor , Party2: you \n",
    "3. AllCursors_eula.txt, Party1: you , Party2: Licensor \n",
    "4. AnyChart_eula.txt, Party1: you , Party2: Sibental\n",
    "5. AOL Inc_eula.txt, Party1: you , Party2: us\n",
    "6. Bitdefender_eula.txt, Party1: you , Party2: BITDEFENDER\n",
    "7. BTC_eula.txt, Party1: you , Party2: bigtincan\n",
    "8. Caphyon_eula.txt, Party1: YOU , Party2: CAPHYON \n",
    "9. CareerBuilder_eula.txt, Party1: you , Party2: CareerBuilder \n",
    "10. Caristix_eula.txt, Party1: you , Party2: Caristix \n",
    "<br>\n",
    "...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FAILED extracts:**\n",
    "\n",
    "1. Google_Construction_Agreement_C.txt, Party1: GOOGLE , Party2: S    \n",
    "2. 2Think1 Solutions Inc_eula.txt, Party1: you , Party2: 2THINK1 \n",
    "3. ALM Works Ltd_eula.txt, Party1: you , Party2: the\n",
    "4. app square OG_eula.txt, Party1: you , Party2: appsquare \n",
    "5. APPEARTOME LIMITED_eula.txt, Party1: you , Party2: Appeartome \n",
    "6. Atlassian_eula.txt, Party1: you , Party2: Atlassian\n",
    "7. Avanquest Software SA_eula.txt, Party1: you , Party2: Avanquest\n",
    "8. Blizzard Entertainment Inc_eula.txt, Party1: Blizzard , Party2: you \n",
    "9. ChemAxon Ltd_eula.txt, Party1: you , Party2: ChemAxon\n",
    "10. Cloudfind Limited_eula.txt, Party1: you , Party2: Cloudfind\n",
    "<br>\n",
    "...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Challenges with current baseline solution:**\n",
    "- Does not capure party names that contain multiple words\n",
    "- Current logic captures the first word after \"between\" for the first party and \"and\" for the second party.  One of the test cases captured the word \"the\" as opposed to the party name.\n",
    "- The major challenge in this approach is adding lines of codes to handle the nuances in the writing style of each agreement. This can result in almost limitless lines of code.\n",
    "\n",
    "**Conclusion**: A more sophisticated solution is needed. Google's Syntaxnet could be applied to process and identify word types/dependencies in a sentence.  These dependencies can then be used to retrieve the correct party names.  Another alternative could be to process the agreement text via a machine learning approach.  With machine learning, an algorithm can be trained to process text and identify target labels (aka party names).  Once an algorithm is successfully trained, the algorithm can be applied to extract party names on unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
